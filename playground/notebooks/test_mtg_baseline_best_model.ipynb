{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[   INFO   ] MusicExtractorSVM: no classifier models were configured by default\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import typing as tp\n",
    "import math\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import ffmpeg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from essentia.standard import *\n",
    "import essentia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(filename, sampleRate=12000, segment_duration=None):\n",
    "    audio = MonoLoader(filename=filename, sampleRate=sampleRate)()\n",
    "\n",
    "    if segment_duration:\n",
    "        segment_duration = round(segment_duration*sampleRate)\n",
    "        segment_start = (len(audio) - segment_duration) // 2\n",
    "        segment_end = segment_start + segment_duration\n",
    "    else:\n",
    "        segment_start = 0\n",
    "        segment_end = len(audio)\n",
    "\n",
    "    if segment_start < 0 or segment_end > len(audio):\n",
    "        raise ValueError('Segment duration is larger than the input audio duration')\n",
    "\n",
    "    return audio[segment_start:segment_end]\n",
    "\n",
    "\n",
    "def melspectrogram(audio, \n",
    "                   sampleRate=12000, frameSize=512, hopSize=256,\n",
    "                   window='hann', zeroPadding=0, center=True,\n",
    "                   numberBands=96, lowFrequencyBound=0, highFrequencyBound=None,\n",
    "                   weighting='linear', warpingFormula='slaneyMel',\n",
    "                   normalize='unit_tri'):\n",
    "\n",
    "    if highFrequencyBound is None:\n",
    "        highFrequencyBound = sampleRate/2\n",
    "    \n",
    "    windowing = Windowing(type=window, normalized=False, zeroPadding=zeroPadding)\n",
    "    spectrum = Spectrum()\n",
    "    melbands = MelBands(numberBands=numberBands,\n",
    "                        sampleRate=sampleRate,\n",
    "                        lowFrequencyBound=lowFrequencyBound, \n",
    "                        highFrequencyBound=highFrequencyBound,\n",
    "                        inputSize=(frameSize+zeroPadding)//2+1,\n",
    "                        weighting=weighting,\n",
    "                        normalize=normalize,\n",
    "                        warpingFormula=warpingFormula,\n",
    "                        type='power')\n",
    "    amp2db = UnaryOperator(type='lin2db', scale=2)\n",
    "\n",
    "    pool = essentia.Pool()\n",
    "    for frame in FrameGenerator(audio, \n",
    "                                frameSize=frameSize, hopSize=hopSize,\n",
    "                                startFromZero=not center):\n",
    "        pool.add('mel', amp2db(melbands(spectrum(windowing(frame)))))\n",
    "\n",
    "    return pool['mel'].T\n",
    "\n",
    "def get_mel(in_audio_file, is_full_audio):\n",
    "    \"\"\"\n",
    "        in_audio_file: input audio file\n",
    "        out_npy_file: output NPY file to store mel-spectrogram\n",
    "        is_full_audio: analyze full audio instead of a centered 29.1s segment\n",
    "    \"\"\"\n",
    "    if is_full_audio:\n",
    "        # Analyze full audio duration.\n",
    "        segment_duration=None\n",
    "    else:\n",
    "        # Duration for the Choi's VGG model.\n",
    "        segment_duration=29.1\n",
    "\n",
    "    audio = load_audio(in_audio_file, segment_duration=segment_duration)\n",
    "    mel = melspectrogram(audio)\n",
    "    return mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_class=15):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        # init bn\n",
    "        self.bn_init = nn.BatchNorm2d(1)\n",
    "\n",
    "        # layer 1\n",
    "        self.conv_1 = nn.Conv2d(1, 64, 3, padding=1)\n",
    "        self.bn_1 = nn.BatchNorm2d(64)\n",
    "        self.mp_1 = nn.MaxPool2d((2, 4))\n",
    "\n",
    "        # layer 2\n",
    "        self.conv_2 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.bn_2 = nn.BatchNorm2d(128)\n",
    "        self.mp_2 = nn.MaxPool2d((2, 4))\n",
    "\n",
    "        # layer 3\n",
    "        self.conv_3 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.bn_3 = nn.BatchNorm2d(128)\n",
    "        self.mp_3 = nn.MaxPool2d((2, 4))\n",
    "\n",
    "        # layer 4\n",
    "        self.conv_4 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.bn_4 = nn.BatchNorm2d(128)\n",
    "        self.mp_4 = nn.MaxPool2d((3, 5))\n",
    "\n",
    "        # layer 5\n",
    "        self.conv_5 = nn.Conv2d(128, 64, 3, padding=1)\n",
    "        self.bn_5 = nn.BatchNorm2d(64)\n",
    "        self.mp_5 = nn.MaxPool2d((4, 4))\n",
    "\n",
    "        # classifier\n",
    "        self.dense = nn.Linear(64, num_class)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "\n",
    "        # init bn\n",
    "        x = self.bn_init(x)\n",
    "\n",
    "        # layer 1\n",
    "        x = self.mp_1(nn.ELU()(self.bn_1(self.conv_1(x))))\n",
    "\n",
    "        # layer 2\n",
    "        x = self.mp_2(nn.ELU()(self.bn_2(self.conv_2(x))))\n",
    "\n",
    "        # layer 3\n",
    "        x = self.mp_3(nn.ELU()(self.bn_3(self.conv_3(x))))\n",
    "\n",
    "        # layer 4\n",
    "        x = self.mp_4(nn.ELU()(self.bn_4(self.conv_4(x))))\n",
    "\n",
    "        # layer 5\n",
    "        x = self.mp_5(nn.ELU()(self.bn_5(self.conv_5(x))))\n",
    "\n",
    "        # classifier\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        logit = nn.Sigmoid()(self.dense(x))\n",
    "\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mel_iter(audio_path:str, window_size) -> tp.Generator[torch.Tensor, None, None]:\n",
    "    mel = get_mel(audio_path, True)\n",
    "    mel = torch.tensor(mel).cuda()\n",
    "    mel_time_dim = mel.shape[1]\n",
    "\n",
    "    for start in range(0, mel.shape[1], window_size):\n",
    "        end = start+window_size\n",
    "        end = end if end <= mel_time_dim else mel_time_dim\n",
    "\n",
    "        yield mel[:, start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(num_class=56)\n",
    "\n",
    "S = torch.load('/home/felipe/Documents/Github/Pt-Brdo/src/pt_brdo/mtg_jamendo_baseline/models/best_model.pth')\n",
    "model.load_state_dict(S)\n",
    "\n",
    "# inference\n",
    "model.eval()\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag_list(option):\n",
    "    if option == 'top50tags':\n",
    "        tag_list = np.load('tag_list_50.npy')\n",
    "    else:\n",
    "        tag_list = np.load('tag_list.npy')\n",
    "        if option == 'genre':\n",
    "            tag_list = tag_list[:87]\n",
    "        elif option == 'instrument':\n",
    "            tag_list = tag_list[87:127]\n",
    "        elif option == 'moodtheme':\n",
    "            tag_list = tag_list[127:]\n",
    "    return list(tag_list)\n",
    "\n",
    "tags = get_tag_list('moodtheme')\n",
    "\n",
    "for idx, tag in enumerate(tags):\n",
    "    tags[idx] = tag.split('---')[-1]\n",
    "\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_out(model_out:torch.Tensor, song:str):\n",
    "\n",
    "    model_out = (model_out * 100)\n",
    "    max_value = math.ceil(model_out.max().item())\n",
    "    model_out = model_out.cpu().detach().numpy()[0]\n",
    "\n",
    "    # set width of bar \n",
    "    barWidth = 0.8\n",
    "    fig, ax = plt.subplots(figsize =(12 , 6)) \n",
    "    print(len(model_out))\n",
    "    # Set position of bar on X axis \n",
    "    br_orig = np.arange(len(model_out))\n",
    "\n",
    "    # Add x, y gridlines\n",
    "    plt.grid(color ='grey',\n",
    "            linestyle ='-.', linewidth = 0.5,\n",
    "            alpha = 0.4)\n",
    "\n",
    "    # Make the plot\n",
    "    plt.bar(br_orig, model_out, color ='r', width = barWidth, edgecolor ='grey') \n",
    "\n",
    "    # Adding Xticks \n",
    "    plt.xlabel('Tags', fontweight ='bold', fontsize = 15) \n",
    "    plt.ylabel('Percentage', fontweight ='bold', fontsize = 15)\n",
    "    plt.xticks([r + barWidth//2 for r in range(len(tags))], tags, rotation='vertical')\n",
    "    plt.yticks([x for x in range(max_value)])\n",
    "    plt.title(song)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moonlight Sonata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "moonlight_path = '/home/felipe/Desktop/moonlight_sonata.mp3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Central 29.1s window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moonlight_segment = get_mel(moonlight_path, False)\n",
    "moonlight_segment = torch.tensor(moonlight_segment).cuda().unsqueeze(0)\n",
    "print(moonlight_segment.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out = model(moonlight_segment)\n",
    "model_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_out(model_out, 'Moonlight Sonata - Cetered 29.1s Segment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prision Song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prision_path = '/home/felipe/Desktop/prison_song.mp3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Central 29.1s window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prision_segment = get_mel(prision_path, False)\n",
    "prision_segment = torch.tensor(prision_segment).cuda().unsqueeze(0)\n",
    "print(prision_segment.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out = model(prision_segment)\n",
    "model_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_out(model_out, 'Prision Song - Cetered 29.1s Segment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 93 milion miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "milion_path = '/home/felipe/Desktop/93_million_miles.mp3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Central 29.1s window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "milion_segment = get_mel(milion_path, False)\n",
    "milion_segment = torch.tensor(milion_segment).cuda().unsqueeze(0)\n",
    "print(milion_segment.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out = model(milion_segment)\n",
    "model_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_out(model_out, '93 Milion Miles - Cetered 29.1s Segment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moonlight_iter = mel_iter(moonlight_path)\n",
    "# my_mel = torch.tensor(my_mel).cuda()\n",
    "# print(my_mel.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
